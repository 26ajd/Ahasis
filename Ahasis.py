import cv2
import numpy as np
from deepface import DeepFace
import tkinter as tk
from tkinter import messagebox, ttk, filedialog
from PIL import Image, ImageTk
import threading
import time
import json
from datetime import datetime
import logging
import os

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class EmotionConfig:
    COLORS = {
        'primary': '#1a1a2e',
        'secondary': '#16213e',
        'accent': '#0f3460',
        'highlight': '#e94560',
        'success': '#00d4aa',
        'warning': '#f39c12',
        'text_light': '#ecf0f1',
        'text_dark': '#2c3e50',
        'background': '#0e1621',
        'card': '#1e2a3a',
        'border': '#34495e'
    }
    EMOTIONS = {
        "happy": {"arabic": "Ø³Ø¹ÙŠØ¯", "emoji": "ğŸ˜Š", "color": "#2ecc71"},
        "sad": {"arabic": "Ø­Ø²ÙŠÙ†", "emoji": "ğŸ˜¢", "color": "#3498db"},
        "angry": {"arabic": "ØºØ§Ø¶Ø¨", "emoji": "ğŸ˜¡", "color": "#e74c3c"},
        "fear": {"arabic": "Ø®Ø§Ø¦Ù", "emoji": "ğŸ˜¨", "color": "#9b59b6"},
        "surprise": {"arabic": "Ù…Ù†Ø¯Ù‡Ø´", "emoji": "ğŸ˜²", "color": "#f39c12"},
        "neutral": {"arabic": "Ù…Ø­Ø§ÙŠØ¯", "emoji": "ğŸ˜", "color": "#95a5a6"},
        "disgust": {"arabic": "Ù…Ø´Ù…Ø¦Ø²", "emoji": "ğŸ¤¢", "color": "#8b4513"}
    }
    CAMERA_SETTINGS = {'width': 640, 'height': 480, 'fps': 30, 'analysis_interval': 0.5}
class CameraSettingsWindow:
    RESOLUTIONS = ["640x480", "720x480", "1280x720"]
    FPS_OPTIONS = [15, 20, 25, 30]
    def __init__(self, parent, camera):
        self.parent = parent
        self.camera = camera
        self.win = tk.Toplevel(parent)
        self.win.title("âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§")
        self.win.geometry("300x250")

        # Ù‡Ù†Ø§ Ù†Ø­Ø¯Ø¯ Ø§Ù„Ø¯Ù‚Ø©
        tk.Label(self.win, text="Ø§Ù„Ø¯Ù‚Ø© (Resolution):").pack(pady=(10,0))
        self.res_var = tk.StringVar(value="640x480")
        self.res_combo = ttk.Combobox(self.win, values=self.RESOLUTIONS, state="readonly", textvariable=self.res_var)
        self.res_combo.pack()

        # Ù‡Ù†Ø§ Ù†Ø­Ø¯Ø¯ Ø¹Ø¯Ø¯ Ø§Ù„ÙØ±ÙŠÙ…Ø§Øª
        tk.Label(self.win, text="Ø¹Ø¯Ø¯ Ø§Ù„ÙØ±ÙŠÙ…Ø§Øª (FPS):").pack(pady=(10,0))
        self.fps_var = tk.IntVar(value=30)
        self.fps_combo = ttk.Combobox(self.win, values=self.FPS_OPTIONS, state="readonly", textvariable=self.fps_var)
        self.fps_combo.pack()

        # Ù‡Ù†Ø§ Ù†Ø­Ø¯Ø¯ ØªØ£Ø®ÙŠØ± Ø§Ù„ØªØ­Ù„ÙŠÙ„
        tk.Label(self.win, text="ØªØ£Ø®ÙŠØ± Ø§Ù„ØªØ­Ù„ÙŠÙ„ (Ø«ÙˆØ§Ù†ÙŠ):").pack(pady=(10,0))
        self.interval_var = tk.DoubleVar(value=EmotionConfig.CAMERA_SETTINGS['analysis_interval'])
        self.interval_slider = ttk.Scale(self.win, from_=0.3, to=2.0, orient='horizontal', variable=self.interval_var)
        self.interval_slider.pack(pady=5, fill='x', padx=20)
        tk.Label(self.win, text="Ø£Ø³Ø±Ø¹ â†   â†’ Ø£Ø¨Ø·Ø£").pack()
        ttk.Button(self.win, text="ØªØ·Ø¨ÙŠÙ‚", command=self.apply).pack(pady=15)
    def apply(self):
        try:
            res = self.res_var.get()
            width, height = map(int, res.split("x"))
            self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, width)
            self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
            fps = int(self.fps_var.get())
            self.camera.set(cv2.CAP_PROP_FPS, fps)
            EmotionConfig.CAMERA_SETTINGS['analysis_interval'] = self.interval_var.get()
            messagebox.showinfo("ØªÙ…", f"ØªÙ… ØªØ­Ø¯ÙŠØ« Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§:\n{width}x{height} @ {fps} FPS\nØªØ£Ø®ÙŠØ± Ø§Ù„ØªØ­Ù„ÙŠÙ„: {self.interval_var.get():.2f} Ø«Ø§Ù†ÙŠØ©")
            self.win.destroy()
        except Exception as e:
            messagebox.showerror("Ø®Ø·Ø£", f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª: {e}")

# Ù‡Ù†Ø§ Ù†Ù‚ÙˆÙ… Ø¨ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
class EmotionAnalyzer:
    def analyze_frame(self, frame):
        try:
            small_frame = cv2.resize(frame, (320, 240))
            result = DeepFace.analyze(
                small_frame,
                actions=['emotion'],
                enforce_detection=False,
                detector_backend='opencv',
                silent=True
            )
            if isinstance(result, list):
                result = result[0]
            # Ù‡Ù†Ø§ Ù†ØµØ­Ø­ Ø¨Ø¹Ø¶ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© ÙÙŠ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
            if result['dominant_emotion'] == 'angry' and result['emotion'].get('disgust',0) > 0.01:
                result['dominant_emotion'] = 'disgust'
            return {
                'dominant_emotion': result['dominant_emotion'],
                'emotions': result['emotion'],
                'timestamp': datetime.now(),
                'confidence': max(result['emotion'].values())
            }
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±: {e}")
            return {
                'dominant_emotion': 'neutral',
                'emotions': {k: 0 for k in EmotionConfig.EMOTIONS.keys()},
                'timestamp': datetime.now(),
                'confidence': 0
            }
# Ù‡Ù†Ø§ Ù†Ù‚ÙˆÙ… Ø¨Ø­ÙØ¸ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
class EmotionStatistics:
    def __init__(self):
        self.emotion_history = []
        self.session_start = datetime.now()

    def add_result(self, result):
        self.emotion_history.append(result)
        if len(self.emotion_history) > 1000:
            self.emotion_history = self.emotion_history[-1000:]
    def export_data(self, filename):
        data = {
            'session_start': self.session_start.isoformat(),
            'total_analyses': len(self.emotion_history),
            'history': [
                {'timestamp': r['timestamp'].isoformat(),
                 'dominant_emotion': r['dominant_emotion'],
                 'confidence': r['confidence'],
                 'emotions': r['emotions']}
                for r in self.emotion_history
            ]
        }
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

# Ù‡Ù†Ø§ Ø´Ø±ÙŠØ· ØªÙ‚Ø¯Ù… Ø­Ø¯ÙŠØ« Ù„ÙƒÙ„ Ø´Ø¹ÙˆØ±
class ModernProgressBar:
    def __init__(self, parent, width=250, height=20, color="#2ecc71"):
        self.canvas = tk.Canvas(parent, width=width, height=height,
                                bg=EmotionConfig.COLORS['card'], highlightthickness=0)
        self.width, self.height, self.color = width, height, color
        self.value, self.max_value = 0, 100
        self.bg_rect = self.canvas.create_rectangle(2,2,width-2,height-2,
                                                    fill=EmotionConfig.COLORS['secondary'],
                                                    outline=EmotionConfig.COLORS['border'])
        self.progress_rect = self.canvas.create_rectangle(2,2,2,height-2, fill=color, outline="")
        self.text = self.canvas.create_text(width//2, height//2, text="0%", fill=EmotionConfig.COLORS['text_light'], font=("Arial", 10, "bold"))
    def set_value(self, value):
        self.value = max(0, min(value, self.max_value))
        progress_width = (self.value / self.max_value) * (self.width - 4)
        self.canvas.coords(self.progress_rect, 2,2,2+progress_width,self.height-2)
        self.canvas.itemconfig(self.text, text=f"{int(self.value)}%")
    def pack(self, **kwargs): self.canvas.pack(**kwargs)
    def grid(self, **kwargs): self.canvas.grid(**kwargs)

#Ù‡Ù†Ø§ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
class EmotionDetectorPro:
    def __init__(self, root):
        self.root = root
        self.analyzer = EmotionAnalyzer()
        self.statistics = EmotionStatistics()
        self.camera_active = False
        self.recording = False
        self.video_writer = None
        self.current_frame = None
        self.imgtk = None
        self.create_interface()
        self.root.protocol("WM_DELETE_WINDOW", self.on_closing)
    def create_interface(self):
        self.root.title("ğŸ­Ahasis")
        self.root.geometry("1400x900")
        self.root.configure(bg=EmotionConfig.COLORS['background'])
        main_frame = tk.Frame(self.root, bg=EmotionConfig.COLORS['background'])
        main_frame.pack(expand=True, fill='both', padx=20, pady=20)

        #Ù‡Ù†Ø§ Ø­Ù‚ Ø¹Ø±Ø¶ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
        video_frame = tk.Frame(main_frame, bg=EmotionConfig.COLORS['card'], bd=2, relief='raised')
        video_frame.pack(side='left', fill='both', expand=True, padx=(0,10))
        tk.Label(video_frame, text="ğŸ“¹ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©", bg=EmotionConfig.COLORS['card'], fg=EmotionConfig.COLORS['text_light'], font=('Arial',14,'bold')).pack(pady=10)
        self.video_label = tk.Label(video_frame, text="ğŸ“· Ø§Ø¶ØºØ· ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§", bg=EmotionConfig.COLORS['secondary'], fg=EmotionConfig.COLORS['text_light'], font=('Arial',16))
        self.video_label.pack(expand=True, fill='both', pady=10)
        # ÙˆÙ‡Ù†Ø§ Ø­Ù‚ Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        results_frame = tk.Frame(main_frame, bg=EmotionConfig.COLORS['card'], bd=2, relief='raised')
        results_frame.pack(side='right', fill='y', padx=(10,0))
        tk.Label(results_frame, text="ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±", font=('Arial',14,'bold'), bg=EmotionConfig.COLORS['card'], fg=EmotionConfig.COLORS['text_light']).pack(pady=10)
        self.current_emotion_label = tk.Label(results_frame, text="ğŸ˜ Ù…Ø­Ø§ÙŠØ¯", font=('Arial',24,'bold'), bg=EmotionConfig.COLORS['card'], fg=EmotionConfig.COLORS['success'])
        self.current_emotion_label.pack(pady=5)
        self.confidence_label = tk.Label(results_frame, text="Ø§Ù„Ø«Ù‚Ø©: 0%", font=('Arial',12), bg=EmotionConfig.COLORS['card'], fg=EmotionConfig.COLORS['text_light'])
        self.confidence_label.pack(pady=5)
        self.emotion_bars = {}
        for k,v in EmotionConfig.EMOTIONS.items():
            bar_frame = tk.Frame(results_frame, bg=EmotionConfig.COLORS['card'])
            bar_frame.pack(fill='x', pady=2)
            lbl = tk.Label(bar_frame, text=f"{v['emoji']} {v['arabic']}", font=('Arial',11,'bold'), bg=EmotionConfig.COLORS['card'], fg=v['color'], width=12, anchor='w')
            lbl.pack(side='left')
            bar = ModernProgressBar(bar_frame, width=180, height=15, color=v['color'])
            bar.pack(side='left', padx=5)
            self.emotion_bars[k] = bar
        controls_frame = tk.Frame(results_frame, bg=EmotionConfig.COLORS['card'])
        controls_frame.pack(pady=20)
        ttk.Button(controls_frame, text="â–¶ ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§", command=self.start_camera).pack(pady=5)
        ttk.Button(controls_frame, text="â¹ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§", command=self.stop_camera).pack(pady=5)
        ttk.Button(controls_frame, text="ğŸ¥ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ", command=self.toggle_recording).pack(pady=5)
        ttk.Button(controls_frame, text="ğŸ’¾ Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", command=self.export_data).pack(pady=5)
        ttk.Button(controls_frame, text="ğŸ“ Ø´Ø±Ø­ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹", command=self.show_project_explanation).pack(pady=5)
        ttk.Button(controls_frame, text="âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§", command=self.open_camera_settings).pack(pady=5)

    # Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
    def start_camera(self):
        if not self.camera_active:
            self.camera = cv2.VideoCapture(0, cv2.CAP_DSHOW)  # Ù…Ù†Ø¹ Ø§Ù„ØºÙ…Ø²
            # self.camera = cv2.VideoCapture("http://192.168.1.3:8080/video")
            #self.camera = cv2.VideoCapture("D:/26ajd/infer5-test.avi")
            self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, EmotionConfig.CAMERA_SETTINGS['width'])
            self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, EmotionConfig.CAMERA_SETTINGS['height'])
            self.camera_active = True
            self.video_loop()
            self.analysis_loop()
            logger.info("ØªÙ… ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±")
    def stop_camera(self):
        self.camera_active = False
        if self.camera:
            self.camera.release()
            self.camera = None
        if self.recording:
            self.toggle_recording()
        self.video_label.config(image='', text='ğŸ“· Ø§Ø¶ØºØ· ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§')
        logger.info("ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§")    
    def open_camera_settings(self):
        if not hasattr(self, "camera") or self.camera is None:
            messagebox.showwarning("ØªÙ†Ø¨ÙŠÙ‡", "Ø´ØºÙ‘Ù„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ø£ÙˆÙ„Ø§Ù‹ Ù‚Ø¨Ù„ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª.")
            return
        CameraSettingsWindow(self.root, self.camera)
#Ù‡Ù†Ø§ Ø§Ù„ÙƒÙ„Ø§Ø³ Ø§Ù„Ø®Ø§Øµ Ø¨Ø¹Ø±Ø¶ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
    def video_loop(self):
        if self.camera_active:
            ret, frame = self.camera.read()
            if ret:
                self.current_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                img = Image.fromarray(self.current_frame)
                img = img.resize((640,480))
                self.imgtk = ImageTk.PhotoImage(img)
                self.video_label.imgtk = self.imgtk
                self.video_label.config(image=self.imgtk)
                # Ù‡Ù†Ø§ Ø­Ù‚ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ùˆ Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¹Ù„ÙŠÙ‡
                if self.recording and self.video_writer:
                    frame_bgr = cv2.cvtColor(self.current_frame, cv2.COLOR_RGB2BGR)
                    if hasattr(self, 'last_result') and self.last_result:
                        dominant = self.last_result['dominant_emotion']
                        emoji = EmotionConfig.EMOTIONS.get(dominant, {'emoji':'','arabic':'Ù…Ø­Ø§ÙŠØ¯'})['emoji']
                        text = f"{emoji} {dominant}"
                        cv2.putText(frame_bgr, text, (10,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)
                    self.video_writer.write(frame_bgr)
            self.root.after(int(1000/EmotionConfig.CAMERA_SETTINGS['fps']), self.video_loop)  
    def analysis_loop(self):
        if self.camera_active and self.current_frame is not None:
            result = self.analyzer.analyze_frame(self.current_frame)
            self.statistics.add_result(result)
            self.last_result = result  # Ù‡Ø°Ø§ Ø¹Ø´Ø§Ù† ÙÙŠ ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
            self.update_ui(result)
            self.root.after(int(EmotionConfig.CAMERA_SETTINGS['analysis_interval']*1000), self.analysis_loop)

    def update_ui(self, result):
        dominant = result['dominant_emotion']
        if dominant not in EmotionConfig.EMOTIONS:
            dominant = 'neutral'
        emoji = EmotionConfig.EMOTIONS[dominant]['emoji']
        color = EmotionConfig.EMOTIONS[dominant]['color']
        confidence = int(result['confidence'])
        self.current_emotion_label.config(text=f"{emoji} {EmotionConfig.EMOTIONS[dominant]['arabic']}", fg=color)
        self.confidence_label.config(text=f"Ø§Ù„Ø«Ù‚Ø©: {confidence}%")
        for k,v in result['emotions'].items():
            if k in self.emotion_bars:
                self.emotion_bars[k].set_value(v)

    def toggle_recording(self):
        if not self.recording and self.camera_active:
            filename = filedialog.asksaveasfilename(defaultextension=".avi", filetypes=[("AVI files","*.avi")])
            if filename:
                fourcc = cv2.VideoWriter_fourcc(*'XVID')
                width = int(self.camera.get(cv2.CAP_PROP_FRAME_WIDTH))
                height = int(self.camera.get(cv2.CAP_PROP_FRAME_HEIGHT))
                self.video_writer = cv2.VideoWriter(filename, fourcc, 20.0, (width, height))
                self.recording = True
                messagebox.showinfo("ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ", f"Ø¨Ø¯Ø£ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ÙˆØ­ÙØ¸ Ø§Ù„Ù…Ù„Ù ÙÙŠ {filename}")
        elif self.recording:
            self.recording = False
            if self.video_writer:
                self.video_writer.release()
            messagebox.showinfo("ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ", "ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ÙˆØ­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­")

    # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    def export_data(self):
        filename = filedialog.asksaveasfilename(defaultextension=".json", filetypes=[("JSON files","*.json")])
        if filename:
            self.statistics.export_data(filename)
            messagebox.showinfo("ØªÙ… Ø§Ù„Ø­ÙØ¸", f"ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ {filename}")

    # Ø´Ø±Ø­ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
    def show_project_explanation(self):
        # Ù†Ø§ÙØ°Ø© Ø¬Ø¯ÙŠØ¯Ø© Ù„Ø¹Ø±Ø¶ Ø§Ù„ÙƒÙˆØ¯ ÙˆØ´Ø±Ø­Ù‡
        window = tk.Toplevel(self.root)
        window.title("ğŸ“– Ø´Ø±Ø­ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„ÙƒØ§Ù…Ù„")
        window.geometry("1000x700")

        # Ø¥Ù†Ø´Ø§Ø¡ Text widget Ù…Ø¹ Scrollbar
        text_frame = tk.Frame(window)
        text_frame.pack(expand=True, fill='both')
        scrollbar = tk.Scrollbar(text_frame)
        scrollbar.pack(side='right', fill='y')
        text = tk.Text(text_frame, wrap="none", font=("Courier New", 10), yscrollcommand=scrollbar.set)
        text.pack(expand=True, fill='both')
        scrollbar.config(command=text.yview)

        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ÙƒÙˆØ¯
        code_path = os.path.abspath(__file__)
        with open(code_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()

        # Ø´Ø±Ø­ Ù„ÙƒÙ„ Ø³Ø·Ø±
        explanations = {
            "import cv2": "OpenCV: Ù„Ø§Ù„ØªÙ‚Ø§Ø· Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„ÙÙŠØ¯ÙŠÙˆ.",
            "import numpy": "NumPy: Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù…ØµÙÙˆÙØ§Øª ÙˆØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±.",
            "from deepface": "DeepFace: Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¹Ø§Ø¨ÙŠØ± Ø§Ù„ÙˆØ¬Ù‡ÙŠØ© ÙˆØ§ÙƒØªØ´Ø§Ù Ø§Ù„Ù…Ø´Ø§Ø¹Ø±.",
            "import tkinter": "Tkinter: Ù„Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø±Ø³ÙˆÙ…ÙŠØ© (GUI).",
            "from tkinter import messagebox": "Ù„Ø¥Ø¸Ù‡Ø§Ø± Ø±Ø³Ø§Ø¦Ù„ Ù…Ù†Ø¨Ø«Ù‚Ø© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù….",
            "from tkinter import ttk": "Ø¹Ù†Ø§ØµØ± ÙˆØ§Ø¬Ù‡Ø© Ø­Ø¯ÙŠØ«Ø© Ù…Ø«Ù„ Ø£Ø²Ø±Ø§Ø± ÙˆØ´Ø±ÙŠØ· Ø§Ù„ØªÙ‚Ø¯Ù….",
            "from tkinter import filedialog": "Ù„Ø¥Ø¸Ù‡Ø§Ø± Ù…Ø±Ø¨Ø¹Ø§Øª Ø­ÙˆØ§Ø± Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…Ù„ÙØ§Øª.",
            "from PIL": "Pillow: Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ± Ø¨ÙŠÙ† OpenCV ÙˆTkinter.",
            "import threading": "Ù„ØªØ´ØºÙŠÙ„ Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø®Ù„ÙÙŠØ© Ø¨Ø¯ÙˆÙ† ØªØ¬Ù…ÙŠØ¯ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©.",
            "import time": "Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ ØªØ£Ø®ÙŠØ±Ø§Øª Ø²Ù…Ù†ÙŠØ© Ø¨ÙŠÙ† Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª.",
            "import json": "Ù„Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ù…Ù„ÙØ§Øª JSON.",
            "from datetime import datetime": "Ù„Ø¥Ø¶Ø§ÙØ© ÙˆÙ‚Øª Ù„ÙƒÙ„ ØªØ­Ù„ÙŠÙ„ Ù…Ø´Ø§Ø¹Ø±.",
            "import logging": "Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙˆØ§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ´ØºÙŠÙ„.",
            "import os": "Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ù…Ù„ÙØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù… ÙˆÙ‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„ÙƒÙˆØ¯ Ù†ÙØ³Ù‡.",
            "class EmotionConfig": "Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø´Ø±ÙˆØ¹: Ø§Ù„Ø£Ù„ÙˆØ§Ù†ØŒ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±ØŒ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§.",
            "class EmotionAnalyzer": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø·Ø§Ø± Ù„Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ù…Ø´Ø§Ø¹Ø± ÙˆØªØµØ­ÙŠØ­ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡.",
            "class EmotionStatistics": "ØªØ®Ø²ÙŠÙ† Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ­ÙØ¸Ù‡Ø§ ÙÙŠ JSON.",
            "class ModernProgressBar": "Ø´Ø±ÙŠØ· ØªÙ‚Ø¯Ù… Ù…Ø±Ø¦ÙŠ Ù„ÙƒÙ„ Ø´Ø¹ÙˆØ±.",
            "class EmotionDetectorPro": "Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ÙˆØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬.",
            "def start_camera": "ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ ÙˆØ¨Ø¯Ø¡ Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ø³ØªÙ…Ø± Ù„Ù„ÙÙŠØ¯ÙŠÙˆ ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„.",
            "def stop_camera": "Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ ÙˆØªØ­Ø±ÙŠØ± Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ ÙˆØ¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ³Ø¬ÙŠÙ„.",
            "def video_loop": "Ø¹Ø±Ø¶ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ÙÙŠ Tkinter ÙˆØªØ³Ø¬ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¥Ø°Ø§ Ù…ÙØ¹Ù„.",
            "def analysis_loop": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ù„ÙƒÙ„ Ø¥Ø·Ø§Ø± ÙˆØªØ­Ø¯ÙŠØ« ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬.",
            "def update_ui": "ØªØ­Ø¯ÙŠØ« ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ø¹ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± ÙˆØ§Ù„Ø«Ù‚Ø© ÙˆØ£Ø´Ø±Ø·Ø© Ø§Ù„ØªÙ‚Ø¯Ù….",
            "def toggle_recording": "Ø¨Ø¯Ø¡ Ø£Ùˆ Ø¥ÙŠÙ‚Ø§Ù ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ÙˆØ­ÙØ¸Ù‡.",
            "def export_data": "Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙÙŠ Ù…Ù„Ù JSON.",
            "def on_closing": "Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ ÙˆØ§Ù„ØªØ³Ø¬ÙŠÙ„ Ø¹Ù†Ø¯ Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚."
        }
        for i, line in enumerate(lines, start=1):
            explanation = ""
            for key in explanations:
                if key in line:
                    explanation = explanations[key]
                    break
            text.insert("end", f"{i:03d}: {line.rstrip()}\n")
            if explanation:
                text.insert("end", f"     âœ {explanation}\n", "explanation")

        text.config(state="disabled") 
    def on_closing(self):
        self.stop_camera()
        self.root.destroy()

if __name__ == "__main__":
    root = tk.Tk()
    app = EmotionDetectorPro(root)
    root.mainloop()

